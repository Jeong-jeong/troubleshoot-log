---
description: Document troubleshooting sessions in PHARL format and optionally upload to Notion
---

# Troubleshoot Log Command

Document troubleshooting discussions with Claude Code in PHARL format.

**IMPORTANT: Always respond in the same language the user is using.**

## Workflow

### Step 1: Analyze Conversation

Review the conversation to identify:
- What problem occurred
- What hypotheses were formed
- What solutions were attempted
- What the results were

### Step 2: Generate PHARL Document

Create a markdown document in this format:

```markdown
# [Title: One-line problem summary]

ğŸ“… **Date**: YYYY-MM-DD
ğŸ·ï¸ **Tags**: `#TAG1`, `#TAG2`, `#TAG3`

---

## ğŸ› Problem

### Symptoms
- Specific problem behavior experienced
- **Include actual error messages verbatim** (copy-paste, not summarize)

```
// Example: Include the ACTUAL error output
TypeError: Cannot read property 'data' of undefined
    at fetchUser (/src/api/user.js:42:15)
    at async handleRequest (/src/handlers/request.js:18:20)
```

### Reproduction Steps
- When does it occur vs when does it work normally
- Specific conditions that trigger the issue

### Environment
- Relevant tech stack, library versions
- Context of the problematic code

## ğŸ” Hypothesis

### Hypothesis 1: [Title]
- **Evidence**: Why this hypothesis was formed (code analysis, logs, etc.)
- **Suspected Cause**: What might be happening internally
- **Verification Method**: How to test this hypothesis

### Hypothesis 2: [Title]
- (Same format)

## ğŸ”§ Attempt

### Attempt 1: [Title]

Write naturally about how this attempt came about. For example:
- "While analyzing the error stack trace, the agent noticed that..."
- "The user suspected that X might be the cause because..."
- "Based on the hypothesis above, we decided to try..."

**Do NOT use "Proposed by: Agent/User" format.** Instead, weave the context naturally into the narrative.

**Approach**

Explain the reasoning in detail:
- What was the core idea behind this attempt?
- Why did this seem like a viable solution given the evidence?
- What specific change or action was taken?

```code
// Include ACTUAL code changes, not pseudocode
// Before:
const data = response.data.user;

// After:
const data = response?.data?.user ?? null;
```

**Result**

Include **actual outputs** - copy-paste real terminal output, error messages, or logs:

```
// GOOD: Actual output
$ npm run build
âœ“ Compiled successfully in 1.2s

// BAD: Summarized
"Build succeeded"
```

- What specific behavior changed after the attempt?
- Did the original error/issue disappear?
- Were there any new errors or side effects?

**Limitations** (If failed)
- Why didn't this approach work?
- What new information did we learn from this failure?

---

### (Separate attempts with horizontal rules)

## ğŸ“Š Result

Use **concrete, measurable values** whenever possible. Avoid vague descriptions.

| Item | Before | After |
|------|--------|-------|
| Error message | `TypeError: Cannot read property 'data' of undefined` | No errors |
| Build output | `âœ— Build failed at webpack step` | `âœ“ Compiled successfully` |
| API response | `500 Internal Server Error` | `200 OK` |
| Test results | `Tests: 8 passed, 2 failed` | `Tests: 10 passed, 0 failed` |

**Bad examples** (avoid these):
- âŒ "Confusion â†’ Clear understanding"
- âŒ "Broken â†’ Fixed"
- âŒ "Error occurred â†’ Error resolved"

**Good examples**:
- âœ… Actual error message â†’ Actual success message
- âœ… Specific metric before â†’ Specific metric after

## ğŸ’¡ Lesson

**IMPORTANT**: This section should NOT be a brief summary. Write in enough detail that someone reading this months later can understand:
1. What you learned
2. Why it matters
3. How to apply it

### Technical Insights

Don't just state facts - explain the "why" and "how":

**Bad example**:
- "marketplace.json is needed for plugin registration"

**Good example**:
- "Claude Codeì˜ í”ŒëŸ¬ê·¸ì¸ ë§ˆì¼“í”Œë ˆì´ìŠ¤ëŠ” ë¶„ì‚° êµ¬ì¡°ë¡œ ì„¤ê³„ë˜ì–´ ìˆë‹¤. ê° ê°œë°œìê°€ ìì‹ ì˜ GitHub ì €ì¥ì†Œì— `marketplace.json`ì„ ìƒì„±í•˜ë©´ í•´ë‹¹ ì €ì¥ì†Œê°€ í•˜ë‚˜ì˜ ë§ˆì¼“í”Œë ˆì´ìŠ¤ê°€ ëœë‹¤. ë‹¤ë¥¸ ì‚¬ìš©ìê°€ ì´ í”ŒëŸ¬ê·¸ì¸ì„ ê²€ìƒ‰í•˜ë ¤ë©´ ë¨¼ì € `/plugin marketplace add [owner/repo]` ëª…ë ¹ì–´ë¡œ í•´ë‹¹ ë§ˆì¼“í”Œë ˆì´ìŠ¤ë¥¼ ìì‹ ì˜ í™˜ê²½ì— ë“±ë¡í•´ì•¼ í•œë‹¤. ì´ëŠ” ì¤‘ì•™ ì§‘ì¤‘ì‹ íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €(npm, pip ë“±)ì™€ ë‹¤ë¥¸ ì ‘ê·¼ ë°©ì‹ì´ë©°, ì»¤ë®¤ë‹ˆí‹° ê³µìœ  ë§ˆì¼“í”Œë ˆì´ìŠ¤(ì˜ˆ: team-attention/plugins-for-claude-natives)ì— PRì„ ë³´ë‚´ë©´ ë” ë„“ì€ ì‚¬ìš©ìì¸µì—ê²Œ ë…¸ì¶œë  ìˆ˜ ìˆë‹¤."

### Design Principles

Explain patterns that can be applied to similar situations:

**Bad example**:
- "Use AskUserQuestion for better UX"

**Good example**:
- "ì‚¬ìš©ìì—ê²Œ ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒì„ ìš”ì²­í•  ë•Œ, í…ìŠ¤íŠ¸ë¡œ 'ì–´ë–¤ ê²ƒì„ ì„ íƒí•˜ì‹œê² ìŠµë‹ˆê¹Œ?'ë¼ê³  ë¬¼ì–´ë³´ë©´ ì‚¬ìš©ìê°€ ì§ì ‘ íƒ€ì´í•‘í•´ì•¼ í•˜ë¯€ë¡œ í† í°ì´ ì†Œëª¨ë˜ê³  ì˜¤íƒ€ ê°€ëŠ¥ì„±ë„ ìˆë‹¤. AskUserQuestion ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ë©´ ì„ íƒì§€ë¥¼ ë²„íŠ¼ìœ¼ë¡œ ì œê³µí•  ìˆ˜ ìˆì–´ì„œ (1) ì‚¬ìš©ì ê²½í—˜ ê°œì„  (2) í† í° ì ˆì•½ (3) ì…ë ¥ ì˜¤ë¥˜ ë°©ì§€ íš¨ê³¼ê°€ ìˆë‹¤. ë‹¨, ì„ íƒì§€ê°€ 2ê°œ ì´ìƒì´ì–´ì•¼ í•˜ë©°, ì‚¬ìš©ìê°€ ììœ ë¡­ê²Œ ì…ë ¥í•˜ê³  ì‹¶ì€ ê²½ìš° 'Other' ì˜µì…˜ì„ í†µí•´ ê°€ëŠ¥í•˜ë‹¤."

### Action Items

Specific, actionable next steps:
- [ ] Concrete task 1
- [ ] Concrete task 2
```

### Step 3: Auto-generate Tags

Automatically add relevant tags to the document (no user confirmation needed):
- **Problem type**: `#NULL_CHECK`, `#RACE_CONDITION`, `#ASYNC`, `#TYPE_ERROR`, `#CONFIG`, `#DEPENDENCY`
- **Domain**: `#API`, `#DATABASE`, `#UI`, `#AUTH`, `#BUILD`, `#TEST`
- **Technology**: Framework/library names like `#REACT`, `#NODE`, `#TYPESCRIPT`

**Tag format**: `#UPPER_SNAKE_CASE`

### Step 4: Ask Where to Save (Use AskUserQuestion)

After showing the generated document, **immediately use AskUserQuestion tool**:

```
Question: "ì–´ë””ì— ì €ì¥í• ê¹Œìš”? (ìˆ˜ì •ì‚¬í•­ ìˆìœ¼ë©´ 'Other'ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”)"
Header: "ì €ì¥ ìœ„ì¹˜"
Options:
  - "Notion" : "Notion í˜ì´ì§€/ë°ì´í„°ë² ì´ìŠ¤ì— ì—…ë¡œë“œ"
  - "ë¡œì»¬ íŒŒì¼" : "ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥"
  - "ì €ì¥ ì•ˆ í•¨" : "ì§€ê¸ˆì€ ì €ì¥í•˜ì§€ ì•ŠìŒ"
multiSelect: false
```

User can select "Other" to request modifications or specify a different destination.

### Step 5: Handle Response & Save

#### If User Selected "Notion"
1. Ask for Notion page/database URL (via AskUserQuestion with "ì´ì „ì— ì‚¬ìš©í•œ í˜ì´ì§€" option + Other for new URL)
2. Use `notion-fetch` to understand structure
3. Save using appropriate method (`notion-create-pages` or `notion-update-page`)

#### If User Selected "ë¡œì»¬ íŒŒì¼"
1. Use AskUserQuestion to ask for save path
   - Provide default path option: `./troubleshoot-logs/YYYY-MM-DD-[title-slug].md`
   - Allow custom path via "Other"
2. Create file using Write tool at user-specified path
3. Confirm saved path

#### If User Selected "Other" (custom input)
Handle based on what they typed:
- **Modification request**: Apply changes, then ask where to save again
- **Other platform** (Obsidian, GitHub, etc.): Check MCP availability, proceed or offer local fallback

#### If User Selected "ì €ì¥ ì•ˆ í•¨"
End the workflow

### Notion-Specific Instructions

When saving to Notion:

1. Ask for Notion page/database URL
2. Use `notion-fetch` to understand the page structure
3. Determine appropriate upload method:
   - **Database**: Add as new row
   - **Page**: Create sub-page or append to body

**Extracting Page ID:**
```
https://www.notion.so/Page-Name-2de27f29d15b8170892af488ed82bf62
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                              This 32-character string is the page ID
```

**Notion MCP Workflow:**
1. `notion-fetch`: Understand page structure
2. `notion-create-pages`: Create new pages/database items
3. `notion-update-page`: Add content to existing pages

## Writing Guidelines

**Core Principle**: The document should allow readers to understand **"why this approach was taken and why it became the solution"** when read later.

### DO's and DON'Ts

#### DO:
- Include actual error messages, terminal outputs, and code snippets (copy-paste)
- Explain the reasoning behind each decision
- Write Lesson section in detail with context and examples
- Describe how ideas evolved during the troubleshooting process

#### DON'T:
- Summarize error messages (e.g., "an error occurred")
- Use vague descriptions (e.g., "fixed the issue")
- Write one-liner lessons without explanation
- Use "Proposed by: Agent/User" format

### Section-by-Section Guide

#### ğŸ› Problem
- **Symptoms**: Include ACTUAL error messages verbatim
- **Reproduction Steps**: Specific conditions
- **Environment**: Tech stack, versions

#### ğŸ” Hypothesis
For each hypothesis:
- **Evidence**: Specific clues from code/logs
- **Suspected Cause**: Detailed reasoning
- **Verification Method**: How to test

#### ğŸ”§ Attempt
Write naturally about how each attempt came about:
- Who noticed what, and why they thought it might help
- Actual code changes (not pseudocode)
- Actual outputs (not summaries)
- If failed, what was learned

#### ğŸ“Š Result
- Before/After with **actual values**
- Error messages, metrics, observable behaviors
- No vague adjectives

#### ğŸ’¡ Lesson
**This is the most important section for future reference.**
- **Technical Insights**: Explain concepts in detail with context
- **Design Principles**: Patterns that can be reused, with reasoning
- **Action Items**: Specific next steps

## Notes

- If the conversation is not related to troubleshooting, inform the user
- Always offer local save as a fallback option
- Respect user's choice of save destination
